version: '3.8'

services:
  # Working launcher
  launcher:
    build: .
    container_name: soulfra_launcher
    ports:
      - "7777:7777"
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    command: python3 -u WORKING_LAUNCHER.py
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7777/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Master orchestrator (fixed imports)
  master:
    build: .
    container_name: soulfra_master
    ports:
      - "8000:8000"
    volumes:
      - ./logs:/app/logs
      - ./soulfra_master.db:/app/soulfra_master.db
    command: python3 -u SOULFRA_MASTER_ORCHESTRATOR.py
    restart: unless-stopped

  # Clean master control
  clean_master:
    build: .
    container_name: soulfra_clean_master
    ports:
      - "8001:8001"
    volumes:
      - ./logs:/app/logs
    command: python3 -u CLEAN_MASTER_CONTROL.py
    restart: unless-stopped

  # Chatlog system
  chatlog:
    build: .
    container_name: soulfra_chatlog
    ports:
      - "8888:8888"
    volumes:
      - ./logs:/app/logs
      - ./chatlog_workspace:/app/chatlog_workspace
    command: python3 -u UNIFIED_CHATLOG_SYSTEM.py
    restart: unless-stopped

  # AI ecosystem (minimal)
  ai_ecosystem:
    build: .
    container_name: soulfra_ai
    ports:
      - "9999:9999"
    volumes:
      - ./logs:/app/logs
    command: python3 -u MINIMAL_AI_ECOSYSTEM.py
    restart: unless-stopped

  # Empire builder (minimal)
  empire:
    build: .
    container_name: soulfra_empire
    ports:
      - "8181:8181"
    volumes:
      - ./logs:/app/logs
      - ./idea_empire_workspace:/app/idea_empire_workspace
    command: python3 -u MINIMAL_EMPIRE_BUILDER.py
    restart: unless-stopped

  # Ollama local AI service
  ollama:
    image: ollama/ollama:latest
    container_name: soulfra_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    restart: unless-stopped
    command: serve
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ollama_data:
